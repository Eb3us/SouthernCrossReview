<!DOCTYPE html>
<html lang="en">
<head>
   <!--text encoding-->
   <meta charset="utf-8">
   <!--title-->
   <title>AI Versus AI</title>
   <!--link to css-->
   <link rel="stylesheet" href="scr.css" type="text/css" media="screen and (min-width: 1000px)" >
   <link rel="stylesheet" href="scrm.css" type="text/css" media="screen and (max-width: 999px)" title="Mobile stylesheet">
   <link href="https://fonts.googleapis.com/css2?family=Indie+Flower&family=Merriweather:wght@300;400;700&display=swap" rel="stylesheet">
   <!--Share Buttons Code-->
   <script type='text/javascript' src='//platform-api.sharethis.com/js/sharethis.js#property=5c41e38a058f100011a5a9ba&product=inline-share-buttons' async='async'></script>
   
   <!--Metas-->
   	<!--For Facebook-->
   		<meta property="og:title" content="AI Versus AI" />
   		<meta property="og:type" content="article" />
   		<meta property="og:image" content="https://southerncrossreview.org/153/ai-vs-ai.jpeg" />
   		<meta property="og:url" content="https://southerncrossreview.org/153/klare-ai-ai.html" />
   		<meta property="og:description" content="" />
   	<!-- For Google -->
   		<meta name="description" content="" />
   		<meta name="keywords" content="" />
   		<meta name="author" content="Michael Klare" />
   
      <script src="./scripts/article-scr.js" defer></script>

</head>
<body>
  <nav><a href="https://southerncrossreview.org" id="nav-title">SouthernCrossReview</a>
    
    <p id="nav-category">Current Events</p>

    <a href="https://southerncrossreview.org" id="home-icon-div"><p id="home-text">HOME</p><img id="home-icon" src="../home.png"></a>
  </nav>

<header>
<h1>AI Versus AI</h1>
<h3>And Human Extinction as Collateral Damage</h3>
<p><img src="ai-vs-ai.jpeg" class="a" alt="ai vs ai"/></p>
<h2>By <a href="https://tomdispatch.com/authors/michaelklare/">Michael Klare</a></h2>


</header>

<main>
<p class="intro">A world in which machines governed by artificial intelligence (AI)
systematically replace human beings in most business, industrial, and
professional functions is horrifying to imagine. After all, as prominent
computer scientists have been warning us, AI-governed systems are <a
href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">prone
to</a> critical errors and inexplicable “hallucinations,” resulting in
potentially catastrophic outcomes. But there’s an even more dangerous
scenario imaginable from the proliferation of super-intelligent
machines: the possibility that those nonhuman entities could end up
fighting one another, obliterating all human life in the process.</p>
<p>The notion that super-intelligent computers might run amok and
slaughter humans has, of course, long been a staple of popular culture.
In the prophetic <a href="https://en.wikipedia.org/wiki/WarGames">1983
film</a> “WarGames,” a supercomputer known as WOPR (for War Operation
Plan Response and, not surprisingly, pronounced “whopper”) nearly
provokes a catastrophic nuclear war between the United States and the
Soviet Union before being disabled by a teenage hacker (played by
Matthew Broderick). The “<a
href="https://en.wikipedia.org/wiki/Terminator_(franchise)">Terminator</a>”
movie franchise, beginning with the original 1984 film, similarly
envisioned a self-aware supercomputer called “Skynet” that, like WOPR,
was designed to control U.S. nuclear weapons but chooses instead to wipe
out humanity, viewing us as a threat to its existence.</p>
<p><span id="anchor"></span>Though once confined to the realm of science
fiction, the concept of supercomputers killing humans has now become a
distinct possibility in the very real world of the near future. In
addition to developing a wide variety of “<a
href="https://www.armscontrol.org/act/2019-03/features/autonomous-weapons-systems-laws-war">autonomous</a>,”
or robotic combat devices, the major military powers are also rushing to
create automated battlefield decision-making systems, or what might be
called “<a href="http://www.tomdispatch.com/blog/176745/">robot
generals</a>.” In wars in the not-too-distant future, such AI-powered
systems could be deployed to deliver combat orders to American soldiers,
dictating where, when, and how they kill enemy troops or take fire from
their opponents. In some scenarios, robot decision-makers could even end
up exercising control over America’s atomic weapons, potentially
allowing them to ignite a nuclear war resulting in humanity’s
demise.</p>
<p>Now, take a breath for a moment. The installation of an AI-powered
command-and-control (C2) system like this may seem a distant
possibility. Nevertheless, the U.S. Department of Defense is working
hard to develop the required hardware and software in a systematic,
increasingly rapid fashion. In its budget submission for 2023, for
example, the Air Force <a
href="https://comptroller.defense.gov/Portals/45/Documents/defbudget/FY2023/FY2023_Budget_Request_Overview_Book.pdf">requested
$231 million</a> to develop the <a
href="https://crsreports.congress.gov/product/pdf/IF/IF11866">Advanced
Battlefield Management System</a> (ABMS), a complex network of sensors
and AI-enabled computers designed to collect and interpret data on enemy
operations and provide pilots and ground forces with a menu of optimal
attack options. As the technology advances, the system <a
href="https://breakingdefense.com/2020/09/abms-demo-proves-ai-chops-for-c2/">will
be capable</a> of sending “fire” instructions directly to “shooters,”
largely bypassing human control.</p>
<p>“A machine-to-machine data exchange tool that provides options for
deterrence, or for on-ramp [a military show-of-force] or early
engagement,” was how Will Roper, assistant secretary of the Air Force
for acquisition, technology, and logistics, <a
href="https://breakingdefense.com/2020/09/roper-mulls-name-change-for-changing-abms-not-skynet/">described</a>
the ABMS system in a 2020 interview. Suggesting that “we do need to
change the name” as the system evolves, Roper added, “I think Skynet is
out, as much as I would love doing that as a sci-fi thing. I just don’t
think we can go there.”</p>
<p>And while he can’t go there, that’s just where the rest of us may,
indeed, be going.</p>
<p>Mind you, that’s only the start. In fact, the Air Force’s ABMS is
intended to constitute the nucleus of a larger constellation of sensors
and computers that will connect <em>all </em>U.S. combat forces, the
Joint All-Domain Command-and-Control System (JADC2, pronounced
“Jad-C-two”). “JADC2 intends to enable commanders to make better
decisions by collecting data from numerous sensors, processing the data
using artificial intelligence algorithms to identify targets, then
recommending the optimal weapon… to engage the target,” the
Congressional Research Service <a
href="https://sgp.fas.org/crs/natsec/IF11493.pdf">reported</a> in
2022.</p>
<p><strong>AI and the Nuclear Trigger</strong></p>
<p>Initially, JADC2 will be designed to coordinate combat operations
among “conventional” or non-nuclear American forces. Eventually,
however, it is expected to <a
href="https://www.armscontrol.org/act/2020-04/features/skynet-revisited-dangerous-allure-nuclear-command-automation">link
up</a> with the Pentagon’s nuclear command-control-and-communications
systems (NC3), potentially giving computers significant control over the
use of the American nuclear arsenal. “JADC2 and NC3 are intertwined,”
General John E. Hyten, vice chairman of the Joint Chiefs of Staff, <a
href="https://breakingdefense.com/2020/02/nuclear-c3-goes-all-domain-gen-hyten/">indicated</a>
in a 2020 interview. As a result, he added in typical Pentagonese, “NC3
has to inform JADC2 and JADC2 has to inform NC3.”</p>
<p>It doesn’t require great imagination to picture a time in the
not-too-distant future when a crisis of some sort — say a U.S.-China
military clash in the South China Sea or near Taiwan — prompts ever more
intense fighting between opposing air and naval forces. Imagine then the
JADC2 ordering the intense bombardment of enemy bases and command
systems in China itself, triggering reciprocal attacks on U.S.
facilities and a lightning decision by JADC2 to retaliate with tactical
nuclear weapons, igniting a long-feared nuclear holocaust.</p>
<a target="_blank" href="https://www.amazon.com/dp/1627792481/ref=nosim/?tag=tomdispatch-20">
<div class="polaroid">
<img class="b" src="all-hell-breaks-loose.png" alt="All Hell Breaking Loose by Michael Klare" style="width:100%">
<div class="container"><p>Buy the Book!</p></div></div></a>
<p>The possibility that nightmare scenarios of this sort could result
in the accidental or unintended onset of nuclear war has long troubled
analysts in the arms control community. But the growing automation of
military C2 systems has generated anxiety not just among them but among
senior national security officials as well.</p>
<p>As early as 2019, when I questioned Lieutenant General Jack Shanahan,
then director of the Pentagon’s Joint Artificial Intelligence Center,
about such a risky possibility, he <a
href="https://breakingdefense.com/2019/09/no-ai-for-nuclear-command-control-jaics-shanahan/">responded</a>,
“You will find no stronger proponent of integration of AI capabilities
writ large into the Department of Defense, but there is one area where I
pause, and it has to do with nuclear command and control.” This “is the
ultimate human decision that needs to be made” and so “we have to be
very careful.” Given the technology’s “immaturity,” he added, we need “a
lot of time to test and evaluate [before applying AI to NC3].”</p>
<p>In the years since, despite such warnings, the Pentagon has been
racing ahead with the development of automated C2 systems. In its budget
submission for 2024, the Department of Defense <a
href="https://comptroller.defense.gov/Portals/45/Documents/defbudget/FY2024/FY2024_Budget_Request.pdf">requested</a>
$1.4 billion for the JADC2 in order “to transform warfighting capability
by delivering information advantage at the speed of relevance across all
domains and partners.” Uh-oh! And then, it requested another $1.8
billion for other kinds of military-related AI research.</p>
<p>Pentagon officials acknowledge that it will be some time before robot
generals will be commanding vast numbers of U.S. troops (and autonomous
weapons) in battle, but they have already launched several projects
intended to test and perfect just such linkages. One example is the
Army’s <a
href="https://crsreports.congress.gov/product/pdf/IF/IF11654/6">Project
Convergence</a>, involving a series of field exercises designed to
validate ABMS and JADC2 component systems. In a test held in August 2020
at the Yuma Proving Ground in Arizona, for example, the Army used a
variety of air- and ground-based sensors to track simulated enemy forces
and then process that data using AI-enabled computers at Joint Base
Lewis McChord in Washington state. Those computers, in turn, issued fire
instructions to ground-based artillery at Yuma. “This entire sequence
was supposedly accomplished within 20 seconds,” the Congressional
Research Service later <a
href="https://crsreports.congress.gov/product/pdf/IF/IF11654/6">reported</a>.</p>
<p>Less is known about the Navy’s AI equivalent, “Project Overmatch,” as
many aspects of its programming have been kept secret. According to
Admiral Michael Gilday, chief of naval operations, Overmatch is <a
href="https://sgp.fas.org/crs/natsec/R46725.pdf">intended</a> “to enable
a Navy that swarms the sea, delivering synchronized lethal and nonlethal
effects from near-and-far, every axis, and every domain.” Little else
has been revealed about the project.</p>
<p><strong>“Flash Wars” and Human Extinction</strong></p>
<p>Despite all the secrecy surrounding these projects, you can think of
ABMS, JADC2, Convergence, and Overmatch as building blocks for a future
Skynet-like mega-network of super-computers designed to command all U.S.
forces, including its nuclear ones, in armed combat. The more the
Pentagon moves in that direction, the closer we’ll come to a time when
AI possesses life-or-death power over all American soldiers along with
opposing forces and any civilians caught in the crossfire.</p>
<p>Such a prospect should be ample cause for concern. To start with,
consider the risk of errors and miscalculations by the algorithms at the
heart of such systems. As top computer scientists have warned us, those
algorithms are <a
href="https://www.nytimes.com/2023/03/29/technology/ai-chatbots-hallucinations.html">capable
of</a> remarkably inexplicable mistakes and, to use the AI term of the
moment, “hallucinations” — that is, seemingly reasonable results that
are entirely illusionary. Under the circumstances, it’s not hard to
imagine such computers “hallucinating” an imminent enemy attack and
launching a war that might otherwise have been avoided.</p>
<p>And that’s not the worst of the dangers to consider. After all,
there’s the obvious likelihood that America’s adversaries will similarly
equip their forces with robot generals. In other words, future wars are
likely to be fought by one set of AI systems against another, both
linked to nuclear weaponry, with entirely unpredictable — but
potentially catastrophic — results.</p>
<p>Not much is known (from public sources at least) about Russian and
Chinese efforts to automate their military command-and-control systems,
but both countries are thought to be developing networks comparable to
the Pentagon’s JADC2. As early as 2014, in fact, Russia inaugurated a
National Defense Control Center (NDCC) in Moscow, a centralized command
post for assessing global threats and initiating whatever military
action is deemed necessary, whether of a non-nuclear or nuclear nature.
Like JADC2, the NDCC is <a
href="https://foxtrotalpha.jalopnik.com/look-inside-putins-massive-new-military-command-and-con-1743399678">designed</a>
to collect information on enemy moves from multiple sources and provide
senior officers with guidance on possible responses.</p>
<p>China is said to be pursuing an even more elaborate, if similar,
enterprise under the rubric of “Multi-Domain Precision Warfare” (MDPW).
According to the Pentagon’s 2022 report on Chinese military
developments, its military, the People’s Liberation Army, is <a
href="../../../../../../../mklar/OneDrive/Pictures/2022-MILITARY-AND-SECURITY-DEVELOPMENTS-INVOLVING-THE-PEOPLES-REPUBLIC-OF-CHINA.PDF">being
trained and equipped</a> to use AI-enabled sensors and computer networks
to “rapidly identify key vulnerabilities in the U.S. operational system
and then combine joint forces across domains to launch precision strikes
against those vulnerabilities.”</p>
<p>Picture, then, a future war between the U.S. and Russia or China (or
both) in which the JADC2 commands all U.S. forces, while Russia’s NDCC
and China’s MDPW command those countries’ forces. Consider, as well,
that all three systems are likely to experience errors and
hallucinations. How safe will humans be when robot generals decide that
it’s time to “win” the war by nuking their enemies?</p>
<p>If this strikes you as an outlandish scenario, think again, at least
according to the leadership of the National Security Commission on
Artificial Intelligence, a congressionally mandated enterprise that was
chaired by Eric Schmidt, former head of Google, and Robert Work, former
deputy secretary of defense. “While the Commission believes that
properly designed, tested, and utilized AI-enabled and autonomous weapon
systems will bring substantial military and even humanitarian benefit,
the unchecked global use of such systems potentially risks unintended
conflict escalation and crisis instability,” it <a
href="https://www.nscai.gov/wp-content/uploads/2021/03/Full-Report-Digital-1.pdf">affirmed</a>
in its Final Report. Such dangers could arise, it stated, “because of
challenging and untested complexities of interaction between AI-enabled
and autonomous weapon systems on the battlefield” — when, that is, AI
fights AI.</p>
<p>Though this may seem an extreme scenario, it’s entirely possible that
opposing AI systems could trigger a catastrophic “flash war” — the
military equivalent of a “flash crash” on Wall Street, when huge
transactions by super-sophisticated trading algorithms spark panic
selling before human operators can restore order. In the infamous “Flash
Crash” of May 6, 2010, computer-driven trading precipitated a 10% fall
in the stock market’s value. <a
href="https://foreignpolicy.com/2018/09/12/a-million-mistakes-a-second-future-of-war/">According
to</a> Paul Scharre of the Center for a New American Security, who first
studied the phenomenon, “the military equivalent of such crises” on Wall
Street would arise when the automated command systems of opposing forces
“become trapped in a cascade of escalating engagements.” In such a
situation, he noted, “autonomous weapons could lead to accidental death
and destruction at catastrophic scales in an instant.”</p>
<p>At present, there are virtually no measures in place to prevent a
future catastrophe of this sort or even talks among the major powers to
devise such measures. Yet, as the National Security Commission on
Artificial Intelligence noted, such crisis-control measures are urgently
needed to integrate “automated escalation tripwires” into such systems
“that would prevent the automated escalation of conflict.” Otherwise,
some catastrophic version of World War III seems all too possible. Given
the dangerous immaturity of such technology and the reluctance of
Beijing, Moscow, and Washington to impose any restraints on the
weaponization of AI, the day when machines could choose to annihilate us
might arrive far sooner than we imagine and the extinction of humanity
could be the collateral damage of such a future war.</p>

</main>

<hr>
<footer>

<p>Copyright 2023 Michael T. Klare</p>
<p>Featured image: <a
href="https://flickr.com/photos/marcusramberg/430115937/in/photolist-E1su2-Ahr6kz-2hzGYaD-2hzLQ7A-Rjnrkp-aobARB-pSJmbX-9armgJ-qRSPdZ-26W9iTn-SuyCF-24btKiS-by1c1V-aobJ64-aPhXFD-q1WHmV-bkYnXC-aoeiCQ-aobqWi-h6L23t-pKgAt1-EcLCzg-aoeqjh-9nY64T-6QWUQF-qgGj6R-aoefwS-2nYqqqw-81SKwA-EaypzL-dWWygY-bukYd6-4XC4CC-bc1yxn-7CAwfq-2ofpEZz-Qxc4C7-8WFXeU-2ofnAUu-dpoymo-9eBosV-2kpLJjF-9eBoxT-7JKiaP-vNiPSo-9eEuoU-b8S8XM-bzqgVu-5rUGfi-aLUBqK">toy
soldier</a> by <a href="https://flickr.com/photos/marcusramberg/">Marcus
Ramberg</a> is licensed under <a
href="https://creativecommons.org/licenses/by-nc/2.0/">CC BY-NC 2.0</a>
/ Flickr</p>
<p><em>Follow TomDispatch on </em><a
href="https://twitter.com/TomDispatch"><em>Twitter</em></a><em> and join
us on </em><a
href="https://www.facebook.com/tomdispatch"><em>Facebook</em></a><em>.
Check out the newest Dispatch Books, John Feffer’s new
dystopian novel, </em><a
href="https://www.amazon.com/dp/1642594644/ref=nosim/?tag=tomdispatch-20">Songlands</a><em> (the
final one in his Splinterlands series), Beverly Gologorsky’s
novel </em><a
href="https://www.amazon.com/dp/1608469077/ref=nosim/?tag=tomdispatch-20">Every
Body Has a Story</a><em>, and Tom Engelhardt’s </em><a
href="https://www.amazon.com/dp/1608469018/ref=nosim/?tag=tomdispatch-20">A
Nation Unmade by War</a><em>, as well as Alfred McCoy’s </em><a
href="https://www.amazon.com/dp/1608467732/ref=nosim/?tag=tomdispatch-20">In
the Shadows of the American Century: The Rise and Decline of U.S. Global
Power</a><em>, John Dower’s </em><a
href="https://www.amazon.com/dp/1608467236/ref=nosim/?tag=tomdispatch-20">The
Violent American Century: War and Terror Since World War II</a>, <em>and
Ann Jones’s</em> <a
href="https://www.amazon.com/dp/1608463710/ref=nosim/?tag=tomdispatch-20">They
Were Soldiers: How the Wounded Return from America’s Wars: The Untold
Story</a>.</p>
<h4><a href="https://tomdispatch.com/authors/michaelklare/">Michael
Klare</a></h4>
<p>Michael T. Klare, a <a
href="https://tomdispatch.com/is-a-chinese-invasion-of-taiwan-imminent/"><em>TomDispatch</em></a><a
href="https://tomdispatch.com/is-a-chinese-invasion-of-taiwan-imminent/"> regular</a>,
is the five-college professor emeritus of peace and world security
studies at Hampshire College and a senior visiting fellow at the Arms
Control Association. He is the author of 15 books, the latest of which
is <a
href="https://www.amazon.com/dp/1627792481/ref=nosim/?tag=tomdispatch-20"><em>All
Hell Breaking Loose: The Pentagon’s Perspective on Climate
Change</em></a>. He is a founder of the <a
href="https://www.saneuschinapolicy.org/">Committee for a Sane
U.S.-China Policy</a>.</p>
<p>Thanks to <a href="https://tomdispatch.com">TomDispatch.com</a></p>


<!--Share Buttons Code-->
<div class="sharethis-inline-share-buttons"></div>
<br>

	<!--comments-->
	<SCRIPT><!-- BEGIN Script
var cry1=String.fromCharCode(109,97,105,108,116,111,58);document.write("<a href=\"");document.write(cry1);document.write("southerncrossreview");document.write(String.fromCharCode(14+50));
document.write("gmail.com");
document.write("?subject=Comment about Michael Klare - AI Versus AI \" onMouseOver=\"self.status='';return true\" onMouseOut=\"self.status='';return true\" onMouseDown=\"self.status='';return true\" >");
document.write("Send us your comments about this article ");
document.write("</a>");
	//END --></SCRIPT>
	<br><br>


	<!--home-button-->
	<p style="text-align:center;margin-top:50px;"><a href="https://southerncrossreview.org"><img alt="HOME" src="../home.gif"><br>Home</a></p>
</footer>
</body>
</html>
